mutate(location_name=ifelse(location_name %in% decrease$location_name, paste0(location_name,"*", sep=""), location_name),
location_name=ifelse(location_name %in% increase$location_name, paste0(location_name,"**", sep=""), location_name)) %>% #,
arrange(date, location_name)
## Set up location vectors for labeling
all_locations <- c(grep("National", dat.plot$location_name, value = T)[1],
unique(dat.plot$location_name[dat.plot$location_name
!= grep("National", dat.plot$location_name, value = T)[1]])) #BE SURE TO UPDATE 'NATIONAL' BASED on CLASSIFICATION
increase.plot <-grep("**", all_locations, value=TRUE, fixed=TRUE) #Added vector for footnote
decrease.plot <-grep("*", all_locations, value=TRUE, fixed=TRUE) #Added vector for footnote
decrease.plot <-decrease.plot[which(!decrease.plot %in% increase.plot)]
plot_retro_flu(model_name)
}
version
pacman::p_load(
tidyverse,       # data management and visualization
flexdashboard,   # dashboard versions of R Markdown reports
shiny,           # interactive figures
plotly,           # interactive figures
sf,            # to manage spatial data using a Simple Feature format
tmap,          # to produce simple maps, works for both interactive and static maps
# janitor,       # to clean column names
ggplot2,
RColorBrewer,
raster,
# tigris,
#  scales,
ggtext,
forcats,
grid,
tidyquant,
RSocrata,
covidHubUtils,
hubEnsembles,
xlsx
)
usstat <- read_sf("C:/Users/rpe5/COVIDashboard stuff/usstateandterr.shp")
pacman::p_load(
tidyverse,
flexdashboard,
shiny,
plotly,
sf,
tmap,
ggplot2,
RColorBrewer,
raster,
ggtext,
forcats,
grid,
tidyquant,
RSocrata,
covidHubUtils,
hubEnsembles,
xlsx
)
userid <- "rpe5"
flusight_path <- "C:/Users/rpe5/Desktop/GitHub/Flusight-forecast-data/"
obspath <- "C:/Users/rpe5/Desktop/GitHub/Flusight-forecast-data/data-truth"
forecast_date = "2022-06-13" # Monday
sixweeks_before_forecast_date = "2022-05-02" # 6 weeks ago Monday
ensemble_code_path = paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-ensemble")
source("Dashboard Functions.R")
output_dir <- paste0(ensemble_code_path, "/", forecast_date, "/")
cast_target = c(paste(1:4, "wk inc flu hosp"))
location_names <- read.csv(paste0(flusight_path, "/data-locations/locations.csv"))
eligible_models = read.csv(paste0(output_dir, "models-to-include-in-ensemble-", forecast_date, ".csv"),
header = TRUE)
models =as.character(eligible_models$model)
file_names = list.files(path = paste0(flusight_path, "/data-forecasts"))
all_models = file_names[!(file_names %in% c("Flusight-baseline", "Flusight-ensemble")) &
!grepl(paste0(".md", collapse = "|"), file_names)]
all_metadata = paste0(flusight_path, "/data-forecasts/", all_models,
"/metadata-", all_models, ".txt")
#Read in forecast data
forecast_data <- load_forecasts_repo(
file_path = paste0(flusight_path, "/data-forecasts/"),
models = models,
targets = c(paste(1:4, "wk ahead inc flu hosp")),
forecast_dates = forecast_date,
hub = "FluSight",
types = "quantile")%>%
rename(full_location_name = location_name) %>%
mutate(full_location_name = case_when(location == "US" ~ "United States",
location != "US" ~ full_location_name))
forecast_data$target <- paste(forecast_data$horizon, forecast_data$temporal_resolution, "ahead", forecast_data$target_variable, sep = " ")
forecast_data1 <- forecast_data %>%
mutate(value = case_when(quantile==0.5 ~ round(value),
quantile<0.5 ~ floor(value),
quantile>0.5 ~ ceiling(value),
type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, model, sep = "_")) %>%
dplyr::rename(location_name = full_location_name) %>%
dplyr::select(target, target_end_date, forecast_date, model, location_name, c(12:34)) %>%
group_by(target, target_end_date, forecast_date, model, location_name) %>%
summarise_all(sum, na.rm = T)
forecast_data1$location_name <- ifelse(forecast_data1$location_name == "United States", "National", forecast_data1$location_name)
dat <- read.csv(paste0("C:/Users/rpe5/Desktop/GitHub/Flusight-forecast-data/data-forecasts/Flusight-ensemble/",forecast_date,"-Flusight-ensemble.csv"))
dat$model <- c(rep("FluSight-Ensemble", nrow(dat)))
dat$location_name <- location_names$location_name[match(dat$location, location_names$location)]
dat1 <- dat %>%
mutate(value = case_when(quantile==0.5 ~ round(value),
quantile<0.5 ~ floor(value),
quantile>0.5 ~ ceiling(value),
type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, model, sep = "_")) %>%
dplyr::select(target, target_end_date, forecast_date, model, location_name, c(7:29)) %>%
group_by(target, target_end_date, forecast_date, model, location_name) %>%
summarise_all(sum, na.rm = T)
dat1$location_name <- ifelse(dat1$location_name == "US", "National", dat1$location_name)
obs <- read.csv("C:/Users/rpe5/Desktop/GitHub/Flusight-forecast-data/data-truth/truth-Incident Hospitalizations.csv") %>%
mutate(wk_end_date = get_next_saturday(as.POSIXct(date, "%y/%m/%d")),
location_name = ifelse(location == 'US', 'National', location_name)) %>%
dplyr::select(-date) %>%
group_by(location_name, wk_end_date) %>%
summarise(value = sum(value)) %>%
ungroup()
obs_data1 <- obs
Locations=intersect(unique(obs_data1$location_name), unique(dat1$location_name))
num_horizons <- 4
cast_target <-c(paste(1:num_horizons, "wk ahead inc flu hosp"))
prob.dat <- dat1[, -c(2:4)]
Prob.Increase_1 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name== .x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[1]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
# prob =  round(1-min(as.numeric(substr(names(quantile),10,14))[which((quantile)>observed.cases)]),digits=3)
prob =  max(round(1-min(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)>observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,NA,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Decrease_1 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[1]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
prob =  max(round(max(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)<observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,0,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Increase_2 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[2]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
# prob =  round(1-min(as.numeric(substr(names(quantile),10,14))[which((quantile)>observed.cases)]),digits=3)
prob =  max(round(1-min(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)>observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,NA,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Decrease_2 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[2]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
prob =  max(round(max(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)<observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,0,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Increase_3 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[3]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
# prob =  round(1-min(as.numeric(substr(names(quantile),10,14))[which((quantile)>observed.cases)]),digits=3)
prob =  max(round(1-min(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)>observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,NA,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Decrease_3 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[3]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
prob =  max(round(max(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)<observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,0,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Increase_4 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[4]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
# prob =  round(1-min(as.numeric(substr(names(quantile),10,14))[which((quantile)>observed.cases)]),digits=3)
prob =  max(round(1-min(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)>observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,NA,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Decrease_4 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[4]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
prob =  max(round(max(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)<observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,0,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
change <-
data.frame(Locations,Prob.Increase_1,Prob.Decrease_1,Prob.Increase_2,Prob.Decrease_2,Prob.Increase_3,Prob.Decrease_3,Prob.Increase_4,Prob.Decrease_4,
num_horizons.wk.point.change =
map_dbl(.x = Locations,
.f = function(.x){
last_obs = filter(obs_data1, wk_end_date == max(wk_end_date)) %>% dplyr::select(location_name, value)
val = last_obs$value[which(last_obs$location_name==.x)[1]]
df=filter(dat1, location_name==.x, target == cast_target[num_horizons])
return(df$quantile_0.5 - val)
})#,
# Last.obs.in1.wk.50.PI =
#   map_chr(.x = "Locations", .f = function(.x){
#     last_obs = filter(obs_data1, wk_end_date == max(wk_end_date)) %>% dplyr::select(location_name, value)
#     val = last_obs$value[which(last_obs$location_name==.x)]
#     df=filter(dat1, location_name==.x, target == "4 wk inc flu hosp")#cast_target[num_horizons])
#     interval = seq(df$quantile_0.25, df$quantile_0.75,1)
#     if(!val %in% interval){return("No (flagged)")}
#     else {return("Yes")}
#   })
)
change[is.na(change)] <- 0
change <- change %>%
mutate(Classification =ifelse(Prob.Decrease_4 >=0.75, #& abs(num_horizons.wk.point.change)>10,
"Decrease",NA),
Classification = ifelse((Prob.Increase_4<0.75 & Prob.Decrease_4 < 0.75),
"Uncertain", Classification),
#Classification = ifelse((Prob.Increase_4>=0.75 | Prob.Decrease_4 >= 0.75),# & abs(num_horizons.wk.point.change)<= 10,
#                      "Uncertain", Classification), #paste0("Uncertain (reclassified, ", num_horizons, "-wk point change <= 10)"), Classification),
Classification = ifelse(Prob.Increase_4>=0.75, #& abs(num_horizons.wk.point.change)>10,
"Increase", Classification)) %>%
arrange(desc(Prob.Increase_4))
change.dat1 <- change
change.dat1$Classification_color <- ifelse(change.dat1$Classification == "Uncertain", "#444444", ifelse(change.dat1$Classification == "Increase", "#D55E00",
ifelse(change.dat1$Classification == "Decrease", "#0072B2", NA)))
#change.dat1 <- change.dat1[-c(54),]
#change.dat1$target_end_date <- as.POSIXct("2021-11-12", format = "%Y-%m-%d")
#usstat <- readRDS("C:/Users/rpe5/COVIDashboard stuff/usgeo.RDS")
usstat <- read_sf("C:/Users/rpe5/COVIDashboard stuff/usstateandterr.shp")
#usstat <- tigris::states(class = "sf")
#change.dat <- merge(usstat, change.dat1[,c(1:5, 8:10)], by.y = "location_name", by.x = "NAME")
change.dat <- merge(usstat, change.dat1, by.y = "Locations", by.x = "NAME")
#change.dat <- change.dat[-c(2),]
#change.dat$NAME
#change.mets1 <- change.dat1[, c(1:3, 8:10)]
change.mets1 <- change.dat1
change.mets1$location_name <- change.mets1$Locations
#change.mets <- change.mets1 %>%
#  pivot_longer(cols = c(-location_name), names_to = "Probability") %>%
#  pivot_wider(names_from = c(location_name))
#forcts <- all.dat %>%
#  filter(target_end_date == max(target_end_date)) %>%
#  filter(model == "Ensemble")
forcts <- dat1
Ens <- dat1
#Ens <- all.dat %>%
#  filter(model == "Ensemble")
#mods <- read_csv(paste0(rundate, "-all-hospitalizations-model-data.csv")) %>%
#  filter(model!="Ensemble") %>%
#  pull(model) %>%
#  unique
#obs_data <- read.csv(paste0(shpt, max(inclusion_dates),"/Other output/", max(inclusion_dates), "-", "reported-hosps-data.csv"))
ensemble_for_display <- "FluSight-Ensemble"
display_targets <- cast_target
display_dates <- c(as.Date(forecast_date) - seq(1, 25))
all_mod_dat <- as.data.frame(rbind(dat1, forecast_data1)) %>% dplyr::select(target, target_end_date, forecast_date, model, location_name, quantile_0.025, quantile_0.25, quantile_0.5, quantile_0.75, quantile_0.975)
source("C:/Users/rpe5/COVIDashboard stuff/Weekly Data/Model names and colors.R")
#source(paste0(ncov19path, "Plotting functions.R"))
#source("Dashboard Functions.R")
sf_use_s2(FALSE)
#plot_usmap(regions = "states", labels = T, data = change.dat) +
#  labs(title = "U.S. States",
#       subtitle = "This is a blank map of the United States.") +
#  theme(panel.background=element_blank())
tmap_options(check.and.fix = T)
tm_shape(change.dat) +
tm_fill("Classification_color",
colorNA = "white", textNA = "Missing", legend.show = F) +
tm_borders()+
tm_view(set.view = c(-84.388, 33.736, 2.5)) +
tm_add_legend(type = "fill", labels = c("Increase", "Decrease", "Uncertain", "Missing"), col = c("#D55E00", "#0072B2", "#444444", "white"))
str(change.dat)
tm_shape(change.dat) +
tm_fill("Classification_color",
colorNA = "white", textNA = "Missing", legend.show = F) +
tm_borders()+
tm_view(set.view = c(-84.388, 33.736, 2.5)) +
tm_add_legend(type = "fill", labels = c("Increase", "Decrease", "Uncertain", "Missing"), col = c("#D55E00", "#0072B2", "#444444", "white"))
tm_shape(change.dat) +
tm_fill("Classification_color",
colorNA = "white", textNA = "Missing", legend.show = F) +
tm_borders()+
tm_view(set.view = c(-84.388, 33.736, 2.5)) +
tm_add_legend(type = "fill", labels = c("Increase", "Decrease", "Uncertain", "Missing"), col = c("#D55E00", "#0072B2", "#444444", "white")) +
tmap_save(filename = "C:/Users/rpe5/COVIDashboard stuff/Weekly Datatestmap.html")
m <- tm_shape(change.dat) +
tm_fill("Classification_color",
colorNA = "white", textNA = "Missing", legend.show = F) +
tm_borders()+
tm_view(set.view = c(-84.388, 33.736, 2.5)) +
tm_add_legend(type = "fill", labels = c("Increase", "Decrease", "Uncertain", "Missing"), col = c("#D55E00", "#0072B2", "#444444", "white"))
m
tmap_save(m, filename = "C:/Users/rpe5/COVIDashboard stuff/Weekly Data/testmap.html")
tmap_save(m, filename = "C:/Users/rpe5/COVIDashboard stuff/Weekly Data/testmap.png")
tmap_save(m, filename = "testmap.png")
library(purrr)
library(dplyr)
library(readr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(ggforce)
library(covidHubUtils)
library(simplets)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#devtools::install_github("reichlab/simplets")
source("fit_baseline_one_location.R")
# Set locations and quantiles
required_quantiles <-
c(0.01, 0.025, seq(0.05, 0.95, by = 0.05), 0.975, 0.99)
required_locations <-
readr::read_csv(file = "https://raw.githubusercontent.com/cdcepi/Flusight-forecast-data/master/data-locations/locations.csv") %>%
dplyr::select("location", "abbreviation")
# The reference_date is the date of the Saturday relative to which week-ahead targets are defined.
# The forecast_date is the Monday of forecast creation.
# The forecast creation date is set to a Monday,
# even if we are delayed and create it Tuesday morning.
reference_date <- lubridate::floor_date(Sys.Date(), unit = "week") - 1
forecast_date <- as.character(reference_date + 2)
# Load data
data <- readr::read_csv("https://raw.githubusercontent.com/cdcepi/Flusight-forecast-data/master/data-truth/truth-Incident%20Hospitalizations.csv") %>%
dplyr::filter(date >= "2021-12-04") %>%
dplyr::arrange(location, date)
location_number <- nrow(required_locations)
# fit baseline models
quantile_forecasts <-
purrr::map_dfr(
required_locations$location,
function(loc) {
print(loc)
location_data <- data %>%
dplyr::filter(location == loc)
location_results <-
fit_baseline_one_location(
reference_date = reference_date,
location_data = location_data,
transformation = "none",
symmetrize = TRUE,
window_size = nrow(data),
taus = required_quantiles
)
return(location_results)
}) %>%
dplyr::select(-model)
if (!dir.exists("weekly-submission/forecasts/Flusight-baseline/")) {
dir.create("weekly-submission/forecasts/Flusight-baseline/",
recursive = TRUE)
}
if (!dir.exists("weekly-submission/plots/Flusight-baseline/")) {
dir.create("weekly-submission/plots/Flusight-baseline/",
recursive = TRUE)
}
base_file <- paste0("/Flusight-baseline/", forecast_date, "-Flusight-baseline")
results_path <- paste0("weekly-submission/forecasts", base_file, ".csv")
plot_path <- paste0("weekly-submission/plots", base_file, ".pdf")
# write forecast submission file
write.csv(quantile_forecasts, file = results_path, row.names = FALSE)
# plot
f <- covidHubUtils::load_forecasts_repo(
file_path = paste0('weekly-submission/forecasts/'),
models = 'Flusight-baseline',
forecast_dates = forecast_date,
locations = NULL,
types = NULL,
targets = NULL,
hub = "FluSight",
verbose = TRUE
)
p <-
covidHubUtils::plot_forecasts(
forecast_data = f,
facet = "~location",
hub = "FluSight",
truth_source = "HealthData",
subtitle = "none",
title = "none",
show_caption = FALSE,
plot = FALSE
) +
scale_x_date(
breaks = "1 month",
date_labels = "%b-%y",
limits = as.Date(c(
reference_date - (7 * 32), reference_date + 28
), format = "%b-%y")
) +
theme(
legend.position = "bottom",
legend.direction = "vertical",
legend.text = element_text(size = 8),
legend.title = element_text(size = 8),
axis.text.x = element_text(angle = 90),
axis.title.x = element_blank()
) +
ggforce::facet_wrap_paginate(
~ location,
scales = "free",
ncol = 2,
nrow = 3,
page = 1
)
n <- n_pages(p)
pdf(
plot_path,
paper = 'A4',
width = 205 / 25,
height = 270 / 25
)
for (i in 1:n) {
suppressWarnings(print(
p + ggforce::facet_wrap_paginate(
~ location,
scales = "free",
ncol = 2,
nrow = 3,
page = i
)
))
}
dev.off()
