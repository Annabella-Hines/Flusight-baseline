type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, target, sep = "_")) %>%
dplyr::select(target, target_end_date, forecast_date, location_name, c(7:27)) %>%
group_by(target, target_end_date, forecast_date, location_name) %>%
summarise_all(sum, na.rm = T)
cov.dat$location_name <- ifelse(cov.dat$location_name == "US", "National", cov.dat$location_name)
cov.dat <- left_join(cov.dat, obs_data1, by = c("target_end_date" = "wk_end_date", "location_name" = "location_name"))
cov.dat$coverage.50 = ifelse(cov.dat$value >= cov.dat$quantile_0.25 & cov.dat$value <= cov.dat$quantile_0.75,T,F)
cov.dat$coverage.95 = ifelse(cov.dat$value >= cov.dat$quantile_0.025 & cov.dat$value <= cov.dat$quantile_0.975,T,F)
Percent.Cov.95 <- cov.dat %>% group_by(target, target_end_date) %>%
summarize(Score = round(100*mean(coverage.95, na.rm = T)))
Percent.Cov.95 <- Percent.Cov.95 %>% dplyr::filter(target_end_date <= as.Date(forecast_date)+30) %>% dplyr::filter(is.na(Score) == F) %>% arrange(target_end_date)
write.csv(Percent.Cov.95, paste0(dashpath,"/Coverage/pastCoverage2022-2023.csv"))
pacman::p_load(
tidyverse,
flexdashboard,
shiny,
plotly,
sf,
tmap,
ggplot2,
RColorBrewer,
raster,
ggtext,
forcats,
grid,
tidyquant,
RSocrata,
covidHubUtils,
hubEnsembles,
xlsx,
kableExtra
)
userid <- "rpe5"
flusight_path <- paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-forecast-data/")
obspath <- paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-forecast-data/data-truth")
dashpath <- paste0("C:/Users/",userid,"/Desktop/GitHub/Flu-Visualizations/Dashboard R Code")
forecast_date = "2022-10-31" # Monday
#sixweeks_before_forecast_date = "2022-05-09" # 6 weeks ago Monday
ensemble_code_path = paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-ensemble")
source("Dashboard Functions.R")
output_dir <- paste0(ensemble_code_path, "/", forecast_date, "/")
cast_target = c(paste(1:4, "wk inc flu hosp"))
location_names <- read.csv(paste0(flusight_path, "/data-locations/locations.csv"))
eligible_models = read.csv(paste0(output_dir, "models-to-include-in-ensemble-", forecast_date, ".csv"),
header = TRUE)
models =as.character(eligible_models$model)
file_names = list.files(path = paste0(flusight_path, "/data-forecasts"))
all_models = file_names[!(file_names %in% c("Flusight-baseline", "Flusight-ensemble")) &
!grepl(paste0(".md", collapse = "|"), file_names)]
all_metadata = paste0(flusight_path, "/data-forecasts/", all_models,
"/metadata-", all_models, ".txt")
#Read in forecast data
forecast_data <- load_forecasts_repo(
file_path = paste0(flusight_path, "/data-forecasts/"),
models = all_models,
targets = c(paste(1:4, "wk ahead inc flu hosp")),
forecast_dates = forecast_date,
hub = "FluSight",
types = "quantile")%>%
rename(full_location_name = location_name) %>%
mutate(full_location_name = case_when(location == "US" ~ "United States",
location != "US" ~ full_location_name))
forecast_data$target <- paste(forecast_data$horizon, forecast_data$temporal_resolution, "ahead", forecast_data$target_variable, sep = " ")
forecast_data1 <- forecast_data %>%
mutate(value = case_when(quantile==0.5 ~ round(value),
quantile<0.5 ~ floor(value),
quantile>0.5 ~ ceiling(value),
type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, model, sep = "_")) %>%
dplyr::rename(location_name = full_location_name) %>%
dplyr::select(target, target_end_date, forecast_date, model, location_name, c(12:34)) %>%
group_by(target, target_end_date, forecast_date, model, location_name) %>%
summarise_all(sum, na.rm = T)
forecast_data1$location_name <- ifelse(forecast_data1$location_name == "United States", "National", forecast_data1$location_name)
dat <- read.csv(paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-forecast-data/data-forecasts/Flusight-ensemble/",forecast_date,"-Flusight-ensemble.csv"))
dat$model <- c(rep("FluSight-Ensemble", nrow(dat)))
dat$location_name <- location_names$location_name[match(dat$location, location_names$location)]
dat1 <- dat %>%
mutate(value = case_when(quantile==0.5 ~ round(value),
quantile<0.5 ~ floor(value),
quantile>0.5 ~ ceiling(value),
type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, model, sep = "_")) %>%
dplyr::select(target, target_end_date, forecast_date, model, location_name, c(7:29)) %>%
group_by(target, target_end_date, forecast_date, model, location_name) %>%
summarise_all(sum, na.rm = T)
dat1$location_name <- ifelse(dat1$location_name == "US", "National", dat1$location_name)
obs <- read.csv(paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-forecast-data/data-truth/truth-Incident Hospitalizations.csv")) %>%
mutate(wk_end_date = get_next_saturday(as.POSIXct(date, "%y/%m/%d")),
location_name = ifelse(location == 'US', 'National', location_name)) %>%
filter(date <= forecast_date) %>%
filter(date >= as.Date("2022-08-29", format = "%Y-%m-%d")) %>%
dplyr::select(-date) %>%
group_by(location_name, wk_end_date) %>%
summarise(value = sum(value)) %>%
ungroup()
obs_data1 <- obs
Locations=intersect(unique(obs_data1$location_name), unique(dat1$location_name))
num_horizons <- 4
cast_target <-c(paste(1:num_horizons, "wk ahead inc flu hosp"))
prob.dat <- dat1[, -c(2:4)]
Prob.Increase_1 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name== .x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[1]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
# prob =  round(1-min(as.numeric(substr(names(quantile),10,14))[which((quantile)>observed.cases)]),digits=3)
prob =  max(round(1-min(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)>observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,NA,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Decrease_1 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[1]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
prob =  max(round(max(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)<observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,0,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Increase_2 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[2]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
# prob =  round(1-min(as.numeric(substr(names(quantile),10,14))[which((quantile)>observed.cases)]),digits=3)
prob =  max(round(1-min(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)>observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,NA,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Decrease_2 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[2]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
prob =  max(round(max(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)<observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,0,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Increase_3 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[3]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
# prob =  round(1-min(as.numeric(substr(names(quantile),10,14))[which((quantile)>observed.cases)]),digits=3)
prob =  max(round(1-min(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)>observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,NA,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Decrease_3 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[3]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
prob =  max(round(max(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)<observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,0,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Increase_4 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[4]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
# prob =  round(1-min(as.numeric(substr(names(quantile),10,14))[which((quantile)>observed.cases)]),digits=3)
prob =  max(round(1-min(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)>observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,NA,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
Prob.Decrease_4 = map_dbl(.x=Locations, .f = function(.x){
observed.deaths=
filter(obs_data1,
location_name==.x) %>%
arrange(wk_end_date) %>%
tail(1) %>%
dplyr::select(value) %>% unlist()
quantile= filter(prob.dat,
# model== ensemble_for_display ,
location_name==.x,
target==cast_target[4]) %>%
dplyr::select(names(prob.dat)[grep("quantile_",names(prob.dat))], target) %>%
unlist()
prob =  max(round(max(as.numeric(substr(names(quantile[2:23]),10,14))[which(as.numeric(quantile)<observed.deaths)], na.rm = T),digits=3),0)
prob=ifelse(is.na(prob),0,prob)
prob=ifelse(observed.deaths==0,0,prob)
prob=ifelse(observed.deaths<0,NA,prob)
return(prob)
})
change <-
data.frame(Locations,Prob.Increase_1,Prob.Decrease_1,Prob.Increase_2,Prob.Decrease_2,Prob.Increase_3,Prob.Decrease_3,Prob.Increase_4,Prob.Decrease_4,
num_horizons.wk.point.change =
map_dbl(.x = Locations,
.f = function(.x){
last_obs = filter(obs_data1, wk_end_date == max(wk_end_date)) %>% dplyr::select(location_name, value)
val = last_obs$value[which(last_obs$location_name==.x)[1]]
df=filter(dat1, location_name==.x, target == cast_target[num_horizons])
return(df$quantile_0.5 - val)
})#,
# Last.obs.in1.wk.50.PI =
#   map_chr(.x = "Locations", .f = function(.x){
#     last_obs = filter(obs_data1, wk_end_date == max(wk_end_date)) %>% dplyr::select(location_name, value)
#     val = last_obs$value[which(last_obs$location_name==.x)]
#     df=filter(dat1, location_name==.x, target == "4 wk inc flu hosp")#cast_target[num_horizons])
#     interval = seq(df$quantile_0.25, df$quantile_0.75,1)
#     if(!val %in% interval){return("No (flagged)")}
#     else {return("Yes")}
#   })
)
change[is.na(change)] <- 0
change <- change %>%
mutate(Classification =ifelse(Prob.Decrease_4 >=0.75, #& abs(num_horizons.wk.point.change)>10,
"Decrease",NA),
Classification = ifelse((Prob.Increase_4<0.75 & Prob.Decrease_4 < 0.75),
"Uncertain", Classification),
#Classification = ifelse((Prob.Increase_4>=0.75 | Prob.Decrease_4 >= 0.75),# & abs(num_horizons.wk.point.change)<= 10,
#                      "Uncertain", Classification), #paste0("Uncertain (reclassified, ", num_horizons, "-wk point change <= 10)"), Classification),
Classification = ifelse(Prob.Increase_4>=0.75, #& abs(num_horizons.wk.point.change)>10,
"Increase", Classification)) %>%
arrange(desc(Prob.Increase_4))
change.dat1 <- change
change.dat1$Classification_color <- ifelse(change.dat1$Classification == "Uncertain", "#444444", ifelse(change.dat1$Classification == "Increase", "#D55E00",
ifelse(change.dat1$Classification == "Decrease", "#0072B2", NA)))
#change.dat1 <- change.dat1[-c(54),]
#change.dat1$target_end_date <- as.POSIXct("2021-11-12", format = "%Y-%m-%d")
#usstat <- readRDS("C:/Users/rpe5/COVIDashboard stuff/usgeo.RDS")
usstat <- read_sf(paste0(dashpath,"/usstateandterr.shp"))
#usstat <- tigris::states(class = "sf")
#change.dat <- merge(usstat, change.dat1[,c(1:5, 8:10)], by.y = "location_name", by.x = "NAME")
change.dat <- merge(usstat, change.dat1, by.y = "Locations", by.x = "NAME")
#change.dat <- change.dat[-c(2),]
#change.dat$NAME
#change.mets1 <- change.dat1[, c(1:3, 8:10)]
change.mets1 <- change.dat1
change.mets1$location_name <- change.mets1$Locations
#change.mets <- change.mets1 %>%
#  pivot_longer(cols = c(-location_name), names_to = "Probability") %>%
#  pivot_wider(names_from = c(location_name))
#forcts <- all.dat %>%
#  filter(target_end_date == max(target_end_date)) %>%
#  filter(model == "Ensemble")
forcts <- dat1
Ens <- dat1
#Ens <- all.dat %>%
#  filter(model == "Ensemble")
#mods <- read_csv(paste0(rundate, "-all-hospitalizations-model-data.csv")) %>%
#  filter(model!="Ensemble") %>%
#  pull(model) %>%
#  unique
#obs_data <- read.csv(paste0(shpt, max(inclusion_dates),"/Other output/", max(inclusion_dates), "-", "reported-hosps-data.csv"))
ensemble_for_display <- "FluSight-Ensemble"
display_targets <- cast_target
display_dates <- c(as.Date(forecast_date) - seq(1, 25))
all_mod_dat <- as.data.frame(rbind(dat1, forecast_data1)) %>% dplyr::select(target, target_end_date, forecast_date, model, location_name, quantile_0.025, quantile_0.25, quantile_0.5, quantile_0.75, quantile_0.975)
source(paste0(dashpath,"/Weekly Data/Model names and colors.R"))
#source(paste0(ncov19path, "Plotting functions.R"))
#source("Dashboard Functions.R")
modelnames <- unique(forecast_data$model)
teamnames <- model_team_names[modelnames]
mandtnames <- as.data.frame(cbind(modelnames, teamnames))
mandtnames <- mandtnames[order(mandtnames$teamnames),]
#cov.dat <- read.csv("forecast-eval-Hospitalizations-coverage-averaged-over-common-locations-Coverage-interval-95-2021-12-13.csv")
oneweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 7, "-Flusight-ensemble.csv")) %>% filter(target == "1 wk ahead inc flu hosp")
twoweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 14, "-Flusight-ensemble.csv")) %>% filter(target == "2 wk ahead inc flu hosp")
threeweek <- read.csv(paste0(flusight_path,"data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 21, "-Flusight-ensemble.csv")) %>% filter(target == "3 wk ahead inc flu hosp")
cov.dat1 <- data.frame(rbind(oneweek, twoweek
))
cov.dat1$location_name <- location_names$location_name[match(cov.dat1$location, location_names$location)]
cov.dat <- cov.dat1 %>%
mutate(value = case_when(quantile==0.5 ~ round(value),
quantile<0.5 ~ floor(value),
quantile>0.5 ~ ceiling(value),
type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, target, sep = "_")) %>%
dplyr::select(target, target_end_date, forecast_date, location_name, c(7:27)) %>%
group_by(target, target_end_date, forecast_date, location_name) %>%
summarise_all(sum, na.rm = T)
cov.dat$location_name <- ifelse(cov.dat$location_name == "US", "National", cov.dat$location_name)
cov.dat <- left_join(cov.dat, obs_data1, by = c("target_end_date" = "wk_end_date", "location_name" = "location_name"))
cov.dat$coverage.50 = ifelse(cov.dat$value >= cov.dat$quantile_0.25 & cov.dat$value <= cov.dat$quantile_0.75,T,F)
cov.dat$coverage.95 = ifelse(cov.dat$value >= cov.dat$quantile_0.025 & cov.dat$value <= cov.dat$quantile_0.975,T,F)
Percent.Cov.95 <- cov.dat %>% group_by(target, target_end_date) %>%
summarize(Score = round(100*mean(coverage.95, na.rm = T)))
old <- read.csv(paste0(dashpath,"/Coverage/pastCoverage2022-2023.csv"))[,-c(1)]
old$target_end_date <- as.Date(old$target_end_date, format = "%Y-%m-%d")
Percent.Cov.95 <- unique(data.frame(rbind(Percent.Cov.95, old)))
Percent.Cov.95 <- Percent.Cov.95 %>% dplyr::filter(target_end_date <= as.Date(forecast_date)+30) %>% dplyr::filter(is.na(Score) == F) %>% arrange(target_end_date)
View(Percent.Cov.95)
write.csv(Percent.Cov.95, paste0(dashpath,"/Coverage/pastCoverage2022-2023.csv"))
forecast_date = "2022-11-07" # Monday
#cov.dat <- read.csv("forecast-eval-Hospitalizations-coverage-averaged-over-common-locations-Coverage-interval-95-2021-12-13.csv")
oneweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 7, "-Flusight-ensemble.csv")) %>% filter(target == "1 wk ahead inc flu hosp")
twoweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 14, "-Flusight-ensemble.csv")) %>% filter(target == "2 wk ahead inc flu hosp")
threeweek <- read.csv(paste0(flusight_path,"data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 21, "-Flusight-ensemble.csv")) %>% filter(target == "3 wk ahead inc flu hosp")
cov.dat1 <- data.frame(rbind(oneweek, twoweek, threeweek
))
cov.dat1$location_name <- location_names$location_name[match(cov.dat1$location, location_names$location)]
cov.dat <- cov.dat1 %>%
mutate(value = case_when(quantile==0.5 ~ round(value),
quantile<0.5 ~ floor(value),
quantile>0.5 ~ ceiling(value),
type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, target, sep = "_")) %>%
dplyr::select(target, target_end_date, forecast_date, location_name, c(7:27)) %>%
group_by(target, target_end_date, forecast_date, location_name) %>%
summarise_all(sum, na.rm = T)
cov.dat$location_name <- ifelse(cov.dat$location_name == "US", "National", cov.dat$location_name)
cov.dat <- left_join(cov.dat, obs_data1, by = c("target_end_date" = "wk_end_date", "location_name" = "location_name"))
cov.dat$coverage.50 = ifelse(cov.dat$value >= cov.dat$quantile_0.25 & cov.dat$value <= cov.dat$quantile_0.75,T,F)
cov.dat$coverage.95 = ifelse(cov.dat$value >= cov.dat$quantile_0.025 & cov.dat$value <= cov.dat$quantile_0.975,T,F)
Percent.Cov.95 <- cov.dat %>% group_by(target, target_end_date) %>%
summarize(Score = round(100*mean(coverage.95, na.rm = T)))
old <- read.csv(paste0(dashpath,"/Coverage/pastCoverage2022-2023.csv"))[,-c(1)]
old$target_end_date <- as.Date(old$target_end_date, format = "%Y-%m-%d")
Percent.Cov.95 <- unique(data.frame(rbind(Percent.Cov.95, old)))
Percent.Cov.95 <- Percent.Cov.95 %>% dplyr::filter(target_end_date <= as.Date(forecast_date)+30) %>% dplyr::filter(is.na(Score) == F) %>% arrange(target_end_date)
View(Percent.Cov.95)
threeweek <- read.csv(paste0(flusight_path,"data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 21, "-Flusight-ensemble.csv")) %>% filter(target == "3 wk ahead inc flu hosp")
View(threeweek)
cov.dat <- cov.dat1 %>%
mutate(value = case_when(quantile==0.5 ~ round(value),
quantile<0.5 ~ floor(value),
quantile>0.5 ~ ceiling(value),
type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, target, sep = "_")) %>%
dplyr::select(target, target_end_date, forecast_date, location_name, c(7:27)) %>%
group_by(target, target_end_date, forecast_date, location_name) %>%
summarise_all(sum, na.rm = T)
cov.dat$location_name <- ifelse(cov.dat$location_name == "US", "National", cov.dat$location_name)
cov.dat$location_name <- ifelse(cov.dat$location_name == "US", "National", cov.dat$location_name)
cov.dat <- left_join(cov.dat, obs_data1, by = c("target_end_date" = "wk_end_date", "location_name" = "location_name"))
View(cov.dat)
cov.dat$coverage.50 = ifelse(cov.dat$value >= cov.dat$quantile_0.25 & cov.dat$value <= cov.dat$quantile_0.75,T,F)
cov.dat$coverage.95 = ifelse(cov.dat$value >= cov.dat$quantile_0.025 & cov.dat$value <= cov.dat$quantile_0.975,T,F)
Percent.Cov.95 <- cov.dat %>% group_by(target, target_end_date) %>%
summarize(Score = round(100*mean(coverage.95, na.rm = T)))
View(cov.dat)
View(cov.dat)
#cov.dat <- read.csv("forecast-eval-Hospitalizations-coverage-averaged-over-common-locations-Coverage-interval-95-2021-12-13.csv")
oneweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 7, "-Flusight-ensemble.csv")) %>% filter(target == "1 wk ahead inc flu hosp")
threeweek <- read.csv(paste0(flusight_path,"data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 21, "-Flusight-ensemble.csv")) %>% filter(target == "3 wk ahead inc flu hosp")
cov.dat <- cov.dat1 %>%
mutate(value = case_when(quantile==0.5 ~ round(value),
quantile<0.5 ~ floor(value),
quantile>0.5 ~ ceiling(value),
type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, target, sep = "_")) %>%
dplyr::select(target, target_end_date, forecast_date, location_name, c(7:27)) %>%
group_by(target, target_end_date, forecast_date, location_name) %>%
summarise_all(sum, na.rm = T)
cov.dat$location_name <- ifelse(cov.dat$location_name == "US", "National", cov.dat$location_name)
cov.dat <- left_join(cov.dat, obs_data1, by = c("target_end_date" = "wk_end_date", "location_name" = "location_name"))
View(cov.dat)
obs <- read.csv(paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-forecast-data/data-truth/truth-Incident Hospitalizations.csv")) %>%
mutate(wk_end_date = get_next_saturday(as.POSIXct(date, "%y/%m/%d")),
location_name = ifelse(location == 'US', 'National', location_name)) %>%
filter(date <= forecast_date) %>%
filter(date >= as.Date("2022-08-29", format = "%Y-%m-%d")) %>%
dplyr::select(-date) %>%
group_by(location_name, wk_end_date) %>%
summarise(value = sum(value)) %>%
ungroup()
obs_data1 <- obs
cov.dat <- left_join(cov.dat, obs_data1, by = c("target_end_date" = "wk_end_date", "location_name" = "location_name"))
cov.dat$coverage.50 = ifelse(cov.dat$value >= cov.dat$quantile_0.25 & cov.dat$value <= cov.dat$quantile_0.75,T,F)
cov.dat$coverage.95 = ifelse(cov.dat$value >= cov.dat$quantile_0.025 & cov.dat$value <= cov.dat$quantile_0.975,T,F)
#cov.dat <- read.csv("forecast-eval-Hospitalizations-coverage-averaged-over-common-locations-Coverage-interval-95-2021-12-13.csv")
oneweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 7, "-Flusight-ensemble.csv")) %>% filter(target == "1 wk ahead inc flu hosp")
twoweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 14, "-Flusight-ensemble.csv")) %>% filter(target == "2 wk ahead inc flu hosp")
threeweek <- read.csv(paste0(flusight_path,"data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 21, "-Flusight-ensemble.csv")) %>% filter(target == "3 wk ahead inc flu hosp")
cov.dat1 <- data.frame(rbind(oneweek, twoweek, threeweek, fourweek))
cov.dat1 <- data.frame(rbind(oneweek, twoweek, threeweek
))
cov.dat1$location_name <- location_names$location_name[match(cov.dat1$location, location_names$location)]
cov.dat <- cov.dat1 %>%
mutate(value = case_when(quantile==0.5 ~ round(value),
quantile<0.5 ~ floor(value),
quantile>0.5 ~ ceiling(value),
type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, target, sep = "_")) %>%
dplyr::select(target, target_end_date, forecast_date, location_name, c(7:27)) %>%
group_by(target, target_end_date, forecast_date, location_name) %>%
summarise_all(sum, na.rm = T)
cov.dat$location_name <- ifelse(cov.dat$location_name == "US", "National", cov.dat$location_name)
cov.dat <- left_join(cov.dat, obs_data1, by = c("target_end_date" = "wk_end_date", "location_name" = "location_name"))
cov.dat$coverage.50 = ifelse(cov.dat$value >= cov.dat$quantile_0.25 & cov.dat$value <= cov.dat$quantile_0.75,T,F)
cov.dat$coverage.95 = ifelse(cov.dat$value >= cov.dat$quantile_0.025 & cov.dat$value <= cov.dat$quantile_0.975,T,F)
Percent.Cov.95 <- cov.dat %>% group_by(target, target_end_date) %>%
summarize(Score = round(100*mean(coverage.95, na.rm = T)))
old <- read.csv(paste0(dashpath,"/Coverage/pastCoverage2022-2023.csv"))[,-c(1)]
old$target_end_date <- as.Date(old$target_end_date, format = "%Y-%m-%d")
Percent.Cov.95 <- unique(data.frame(rbind(Percent.Cov.95, old)))
Percent.Cov.95 <- Percent.Cov.95 %>% dplyr::filter(target_end_date <= as.Date(forecast_date)+30) %>% dplyr::filter(is.na(Score) == F) %>% arrange(target_end_date)
View(Percent.Cov.95)
write.csv(Percent.Cov.95, paste0(dashpath,"/Coverage/pastCoverage2022-2023.csv"))
cov.dat1 <- Percent.Cov.95 %>% filter(target == "1 wk ahead inc flu hosp")
cov.dat2 <- Percent.Cov.95 %>% filter(target == "2 wk ahead inc flu hosp")
cov.dat3 <- Percent.Cov.95 %>% filter(target == "3 wk ahead inc flu hosp")
cov.dat4 <- Percent.Cov.95 %>% filter(target == "4 wk ahead inc flu hosp")
cov.dat1$Score100 <- cov.dat1$Score
covplot <- plot_ly() %>%
add_trace(data = cov.dat1, type = "scatter", mode = "lines", fill = "tozeroy", x = ~target_end_date, y = ~Score100, name = "Score100") %>%
layout(showlegend = F, yaxis = list(range = c(0, 100), zerolinecolor = "#ffff", zerolinewidth = 2, gridcolor = "ffff", title = "Percent Coverage (%)", titlefont = list(size = 12)), xaxis = list(zerolinecolor = "#ffff", zerolinewidth = 2, gridcolor = "ffff", title = "1 week ahead Target Date"), plot_bgcolor = "#e5ecf6")
options(warn = -1)
covplot
cov.dat2$Score100 <- cov.dat2$Score
covplot <- plot_ly() %>%
add_trace(data = cov.dat2, type = "scatter", mode = "lines", fill = "tozeroy", x = ~target_end_date, y = ~Score100, name = "Score100") %>%
layout(showlegend = F, yaxis = list(range = c(0, 100), zerolinecolor = "#ffff", zerolinewidth = 2, gridcolor = "ffff", title = "Percent Coverage (%)", titlefont = list(size = 12)), xaxis = list(zerolinecolor = "#ffff", zerolinewidth = 2, gridcolor = "ffff", title = "2 week ahead Target Date"), plot_bgcolor = "#e5ecf6")
options(warn = -1)
covplot
cov.dat3$Score100 <- cov.dat3$Score
covplot
cov.dat4$Score100 <- cov.dat4$Score
covplot <- plot_ly() %>%
add_trace(data = cov.dat4, type = "scatter", mode = "lines", fill = "tozeroy", x = ~target_end_date, y = ~Score100, name = "Score100") %>%
layout(showlegend = F, yaxis = list(range = c(0, 100), zerolinecolor = "#ffff", zerolinewidth = 2, gridcolor = "ffff", title = "Percent Coverage (%)", titlefont = list(size = 12)), xaxis = list(zerolinecolor = "#ffff", zerolinewidth = 2, gridcolor = "ffff", title = "4 week ahead Target Date"), plot_bgcolor = "#e5ecf6")
options(warn = -1)
covplot
