summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage95 = sum(coverage.95)/4) %>%
mutate(model_color = ifelse(model == "Flusight-baseline", "red", ifelse(model == "Flusight-ensemble", "green", "gray")))
coverage95_flusight <- coverage95 %>% filter(model %in% c("Flusight-baseline", "Flusight-ensemble"))
coverage95_not_flusight <- coverage95 %>% filter(model %!in% c("Flusight-baseline", "Flusight-ensemble"))
g <- ggplot(coverage95_flusight, aes(x = forecast_date,
y = coverage95, group = model,
col = model)) +
geom_line(size = 1) + geom_point(size = 2) +
scale_color_manual(values = c("red", "green")) +
geom_line(data = coverage95_not_flusight, aes(x = forecast_date, y = coverage95, group = model), color = adjustcolor("grey", .5)) +
labs(y = "95% Coverage",
x = "",
color = "Model",
title = "95% Coverage by Model") +
scale_x_date(date_breaks = "2 weeks", date_labels = "%d %b %Y") +
theme(axis.text.x = element_text(angle = 60, hjust = 1), panel.grid = element_blank())
coverage50 <- scores %>% filter(location_name == "National") %>%
# filter(target == "4 wk ahead inc flu hosp") %>%
group_by(model, forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage50 = sum(coverage.50)/4) %>%
mutate(model_color = ifelse(model == "Flusight-baseline", "red", ifelse(model == "Flusight-ensemble", "green", "gray")))
coverage50_flusight <- coverage50 %>% filter(model %in% c("Flusight-baseline", "Flusight-ensemble"))
coverage50_not_flusight <- coverage50 %>% filter(model %!in% c("Flusight-baseline", "Flusight-ensemble"))
g <- ggplot(coverage50_flusight, aes(x = forecast_date,
y = coverage50, group = model,
col = model)) +
geom_line(size = 1) + geom_point(size = 2) +
scale_color_manual(values = c("red", "green")) +
geom_line(data = coverage50_not_flusight, aes(x = forecast_date, y = coverage50, group = model), color = adjustcolor("grey", .5)) +
labs(y = "50% Coverage",
x = "",
color = "Model",
title = "50% Coverage by Model") +
scale_x_date(date_breaks = "2 weeks", date_labels = "%d %b %Y") +
theme(axis.text.x = element_text(angle = 60, hjust = 1), panel.grid = element_blank())
#theme_minimal()
g
coverage95_states <- scores %>% filter(location_name != "National") %>%
filter(target == "1 wk ahead inc flu hosp") %>%
group_by(model, target_end_date) %>%
summarise(model = model,
target_end_date = as.Date(target_end_date, format = "%Y-%m-%d"),
coverage95 = mean(coverage.95)) %>%
mutate(model_color = ifelse(model == "Flusight-baseline", "red", ifelse(model == "Flusight-ensemble", "green", "gray")))
coverage95_flusight <- coverage95_states %>% filter(model %in% c("Flusight-baseline", "Flusight-ensemble"))
coverage95_not_flusight <- coverage95_states %>% filter(model %!in% c("Flusight-baseline", "Flusight-ensemble"))
g <- ggplot(coverage95_flusight, aes(x = target_end_date,
y = coverage95, group = model,
col = model)) +
geom_line(size = 1) + geom_point(size = 2) +
#scale_color_manual(values = c("red", "green")) +
geom_line(data = coverage95_not_flusight, aes(x = target_end_date, y = coverage95, group = model), color = adjustcolor("grey", .5)) +
labs(y = "95% Coverage",
x = "",
color = "Model",
title = "1 Week Ahead 95% Coverage by Model") +
scale_x_date(date_breaks = "2 weeks", date_labels = "%d %b %Y") +
theme(axis.text.x = element_text(angle = 60, hjust = 1), panel.grid = element_blank())
#theme_minimal()
g
coverage95_states <- scores %>% filter(location_name != "National") %>%
filter(target == "4 wk ahead inc flu hosp") %>%
group_by(model, target_end_date) %>%
summarise(model = model,
target_end_date = as.Date(target_end_date, format = "%Y-%m-%d"),
coverage95 = mean(coverage.95)) %>%
mutate(model_color = ifelse(model == "Flusight-baseline", "red", ifelse(model == "Flusight-ensemble", "green", "gray")))
coverage95_flusight <- coverage95_states %>% filter(model %in% c("Flusight-baseline", "Flusight-ensemble"))
coverage95_not_flusight <- coverage95_states %>% filter(model %!in% c("Flusight-baseline", "Flusight-ensemble"))
p <- ggplot(coverage95_flusight, aes(x = target_end_date,
y = coverage95, group = model,
col = model)) +
geom_line(size = 1) + geom_point(size = 2) +
#scale_color_manual(values = c("red", "green")) +
geom_line(data = coverage95_not_flusight, aes(x = target_end_date, y = coverage95, group = model), color = adjustcolor("grey", .5)) +
labs(y = "95% Coverage",
x = "",
color = "Model",
title = "4 Week Ahead 95% Coverage by Model") +
scale_x_date(date_breaks = "2 weeks", date_labels = "%d %b %Y") +
theme(axis.text.x = element_text(angle = 60, hjust = 1), panel.grid = element_blank())
coverage95_summary_all <- scores %>%  filter(model != "Flusight-ensemble") %>% filter(location_name != "National") %>%
filter(target == "1 wk ahead inc flu hosp") %>%
group_by(model, forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage95 = sum(coverage.95)/locationcount) #%>%
locationcount <- length(unique(scores$location_name)) - 1
coverage95_summary <- scores %>%  filter(model == "Flusight-ensemble") %>% filter(location_name != "National") %>%
filter(target == "1 wk ahead inc flu hosp") %>%
group_by(forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage95 = sum(coverage.95)/locationcount) #%>%
coverage50_summary <- scores %>% filter(model == "Flusight-ensemble") %>% filter(location_name != "National") %>%
filter(target == "1 wk ahead inc flu hosp") %>%
group_by(forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage50 = sum(coverage.50)/locationcount)# %>%
summary(coverage95_summary$coverage95)
summary(coverage50_summary$coverage50)
coverage95_summary_all <- scores %>%  filter(model != "Flusight-ensemble") %>% filter(location_name != "National") %>%
filter(target == "1 wk ahead inc flu hosp") %>%
group_by(model, forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage95 = sum(coverage.95)/locationcount) #%>%
coverage50_summary_all <- scores %>% filter(model != "Flusight-ensemble") %>% filter(location_name != "National") %>%
filter(target == "1 wk ahead inc flu hosp") %>%
group_by(model, forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage50 = sum(coverage.50)/locationcount)# %>%
# mutate(model_color = ifelse(model == "Flusight-baseline", "red", ifelse(model == "Flusight-ensemble", "green", "gray")))
summary(coverage95_summary_all$coverage95)
summary(coverage50_summary_all$coverage50)
coverage95_summary_all2 <- scores %>%  filter(model != "Flusight-ensemble") %>% filter(location_name != "National") %>%
filter(target == "2 wk ahead inc flu hosp") %>%
group_by(model, forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage95 = sum(coverage.95)/locationcount) #%>%
View(coverage95_summary)
View(coverage95_summary_all)
coverage95_summary_all <- scores %>%  filter(model != "Flusight-ensemble") %>% filter(location_name != "National") %>%
filter(target == "1 wk ahead inc flu hosp") %>%
group_by(model, forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage95 = sum(coverage.95)/locationcount) %>% unique()
coverage95_summary_all2 <- scores %>%  filter(model != "Flusight-ensemble") %>% filter(location_name != "National") %>%
filter(target == "2 wk ahead inc flu hosp") %>%
group_by(model, forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage95 = sum(coverage.95)/locationcount) %>% unique()
View(coverage95_summary_all)
View(coverage95_summary_all)
coverage95_summary_all2 <- scores %>%  filter(model != "Flusight-ensemble") %>% filter(location_name != "National") %>%
filter(target == "2 wk ahead inc flu hosp") %>%
group_by(model, forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage95 = sum(coverage.95)/locationcount) %>% unique() %>%
group_by(model) %>% summarise(model = model,
avg = mean(coverage95))
View(coverage95_summary_all2)
coverage95_summary_all2 <- scores %>%  filter(model != "Flusight-ensemble") %>% filter(location_name != "National") %>%
filter(target == "2 wk ahead inc flu hosp") %>%
group_by(model, forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage95 = sum(coverage.95)/locationcount) %>% unique() %>%
group_by(model) %>% summarise(model = model,
avg = mean(coverage95)) %>% unique()
View(coverage95_summary_all2)
coverage95_summary_all <- scores %>%  filter(model != "Flusight-ensemble") %>% filter(location_name != "National") %>%
filter(target == "1 wk ahead inc flu hosp") %>%
group_by(model, forecast_date) %>%
summarise(model = model,
forecast_date = as.Date(forecast_date, format = "%Y-%m-%d"),
coverage95 = sum(coverage.95)/locationcount) %>% unique() %>%
group_by(model) %>% summarise(model = model,
avg = mean(coverage95)) %>% unique()
View(coverage95_summary_all)
library(tidyverse)
library(covidHubUtils)
library(ggridges)
library(viridis)
library(cowplot)
userid <- "rpe5"
scores <- read.csv(paste0("C:/Users/",userid,"/Desktop/GitHub/Flu-Visualizations/Dashboard R Code/WIS Ranks Data/WIS_Season.csv"))
inc_scores_overall <- scores %>%
# filter(include_overall == "TRUE") %>%
group_by(target_end_date, target, location_name) %>%
mutate(n_models = n()) %>%
##filter(n_models >= 15) %>%
arrange(WIS) %>%
mutate(model_rank = row_number(), rank_percentile = model_rank/n_models) %>%
arrange(-WIS) %>%
mutate(rev_rank = (row_number()-1)/(n_models-1)) %>%
ungroup() %>%
mutate(model = reorder(model, rev_rank, FUN=function(x) quantile(x, probs=0.25, na.rm=TRUE)))
# number of unique opportunities for a prediction
inc_scores_overall %>%
group_by(target_end_date, location_name, target) %>%
summarize(n()) %>%
nrow()
## average rank
inc_scores_overall %>%
group_by(model) %>%
summarize(average_rank = mean(model_rank), total_n = n(),
n_top_rank = sum(model_rank==1), pct_top = n_top_rank/total_n*100) %>%
print(n=Inf)
## average rank
average_rank_percent <- inc_scores_overall %>%
group_by(model) %>%
summarize(average_rank = mean(rev_rank), total_n = n(),
n_top50 = sum(rev_rank> 0.5) , pct_top50 = n_top50/total_n*100) %>%
print(n=Inf) %>% arrange(-pct_top50)
average_rank_percent
View(average_rank_percent)
library(lubridate)
library(tidyverse)
library(covidHubUtils)
library(surveillance)
library(tidytext)
library(stringr)
userid <- "rpe5"
theme_set(theme_bw())
scores <- read.csv(paste0("C:/Users/",userid,"/Desktop/GitHub/Flu-Visualizations/Dashboard R Code/WIS Ranks Data/WIS_scores_Location.csv"))
scores_order <- read.csv(paste0("C:/Users/",userid,"/Desktop/GitHub/Flu-Visualizations/Dashboard R Code/WIS Ranks Data/WIS_inc.rankings_all.csv"))
levels_order <- scores_order$Model
fig_wis_loc <- ggplot(scores,
aes(x = factor(model, levels = levels_order), y=location_name,
fill= scales::oob_squish(relative_WIS, range = c(- 2.584963, 2.584963)))) +
geom_tile() +
geom_text(aes(label = signif(relative_WIS, 2)), size = 2.5) + # I adapted the rounding
scale_fill_gradient2(low = "blue", high = "red", midpoint = 1, na.value = "grey50",
name = "Relative WIS",
breaks = c(-2,-1,0,1,2),
labels =c("0.25", 0.5, 1, 2, 4)) +
xlab(NULL) + ylab(NULL) +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7),
#                            color=ifelse(
#                              levels(average_by_loc_to_plot$model) %in% models_to_highlight,
#                              "red", "black")),
axis.title.x = element_text(size = 9),
axis.text.y = element_text(size = 9),
title = element_text(size = 9)) +
scale_y_discrete(limits = rev)
View(scores)
scores$below <- ifelse(scores$relative_WIS < 1, 1, 0)
belowbase <- scores %>% group_by(model) %>% summarise(model = model,
below_pct = mean(below)*100)
View(belowbase)
belowbase <- scores %>% group_by(model) %>% summarise(model = model,
below_pct = mean(below)*100) %>% unique()
View(belowbase)
library(purrr)
library(dplyr)
library(readr)
library(tidyr)
library(lubridate)
library(ggplot2)
library(ggforce)
library(covidHubUtils)
library(simplets)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#devtools::install_github("reichlab/simplets")
source("fit_baseline_one_location.R")
# Set locations and quantiles
required_quantiles <-
c(0.01, 0.025, seq(0.05, 0.95, by = 0.05), 0.975, 0.99)
required_locations <-
readr::read_csv(file = "https://raw.githubusercontent.com/cdcepi/Flusight-forecast-data/master/data-locations/locations.csv") %>%
dplyr::select("location", "abbreviation")
# The reference_date is the date of the Saturday relative to which week-ahead targets are defined.
# The forecast_date is the Monday of forecast creation.
# The forecast creation date is set to a Monday,
# even if we are delayed and create it Tuesday morning.
reference_date <- lubridate::floor_date(Sys.Date(), unit = "week") - 1
forecast_date <- as.character(reference_date + 2)
# Load data
data <- readr::read_csv("https://raw.githubusercontent.com/cdcepi/Flusight-forecast-data/master/data-truth/truth-Incident%20Hospitalizations.csv") %>%
dplyr::filter(date >= "2021-12-04") %>%
dplyr::arrange(location, date)
location_number <- nrow(required_locations)
# fit baseline models
quantile_forecasts <-
purrr::map_dfr(
required_locations$location,
function(loc) {
print(loc)
location_data <- data %>%
dplyr::filter(location == loc)
location_results <-
fit_baseline_one_location(
reference_date = reference_date,
location_data = location_data,
transformation = "none",
symmetrize = TRUE,
window_size = nrow(data),
taus = required_quantiles
)
return(location_results)
}) %>%
dplyr::select(-model)
if (!dir.exists("weekly-submission/forecasts/Flusight-baseline/")) {
dir.create("weekly-submission/forecasts/Flusight-baseline/",
recursive = TRUE)
}
if (!dir.exists("weekly-submission/plots/Flusight-baseline/")) {
dir.create("weekly-submission/plots/Flusight-baseline/",
recursive = TRUE)
}
base_file <- paste0("/Flusight-baseline/", forecast_date, "-Flusight-baseline")
results_path <- paste0("weekly-submission/forecasts", base_file, ".csv")
plot_path <- paste0("weekly-submission/plots", base_file, ".pdf")
# write forecast submission file
write.csv(quantile_forecasts, file = results_path, row.names = FALSE)
# plot
f <- covidHubUtils::load_forecasts_repo(
file_path = paste0('weekly-submission/forecasts/'),
models = 'Flusight-baseline',
forecast_dates = forecast_date,
locations = NULL,
types = NULL,
targets = NULL,
hub = "FluSight",
verbose = TRUE
)
p <-
covidHubUtils::plot_forecasts(
forecast_data = f,
facet = "~location",
hub = "FluSight",
truth_source = "HealthData",
subtitle = "none",
title = "none",
show_caption = FALSE,
plot = FALSE
) +
scale_x_date(
breaks = "1 month",
date_labels = "%b-%y",
limits = as.Date(c(
reference_date - (7 * 32), reference_date + 28
), format = "%b-%y")
) +
theme(
legend.position = "bottom",
legend.direction = "vertical",
legend.text = element_text(size = 8),
legend.title = element_text(size = 8),
axis.text.x = element_text(angle = 90),
axis.title.x = element_blank()
) +
ggforce::facet_wrap_paginate(
~ location,
scales = "free",
ncol = 2,
nrow = 3,
page = 1
)
n <- n_pages(p)
pdf(
plot_path,
paper = 'A4',
width = 205 / 25,
height = 270 / 25
)
for (i in 1:n) {
suppressWarnings(print(
p + ggforce::facet_wrap_paginate(
~ location,
scales = "free",
ncol = 2,
nrow = 3,
page = i
)
))
}
dev.off()
pacman::p_load(
tidyverse,
flexdashboard,
shiny,
plotly,
sf,
tmap,
ggplot2,
RColorBrewer,
raster,
ggtext,
forcats,
grid,
tidyquant,
RSocrata,
covidHubUtils,
hubEnsembles,
xlsx,
kableExtra
)
userid <- "rpe5"
forecast_date = "2023-01-23" # Monday
options(scipen = 999)
flusight_path <- paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-forecast-data/")
obspath <- paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-forecast-data/data-truth")
dashpath <- paste0("C:/Users/",userid,"/Desktop/GitHub/Flu-Visualizations/Dashboard R Code")
#sixweeks_before_forecast_date = "2022-05-09" # 6 weeks ago Monday
ensemble_code_path = paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-ensemble")
source("C:/Users/rpe5/Desktop/GitHub/Flu-Visualizations/Dashboard R Code/Dashboard Functions.R")
output_dir <- paste0(ensemble_code_path, "/", forecast_date, "/")
cast_target = c(paste(1:4, "wk inc flu hosp"))
location_names <- read.csv(paste0(flusight_path, "/data-locations/locations.csv"))
obs <- read.csv(paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-forecast-data/data-truth/truth-Incident Hospitalizations.csv")) %>%
mutate(wk_end_date = get_next_saturday(as.POSIXct(date, "%y/%m/%d")),
location_name = ifelse(location == 'US', 'National', location_name)) %>%
filter(date <= forecast_date) %>%
filter(date >= as.Date("2022-08-29", format = "%Y-%m-%d")) %>%
dplyr::select(-date) %>%
group_by(location_name, wk_end_date) %>%
summarise(value = sum(value)) %>%
ungroup()
obs_data1 <- obs
oneweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 7, "-Flusight-ensemble.csv")) %>% filter(target == "1 wk ahead inc flu hosp")
twoweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 14, "-Flusight-ensemble.csv")) %>% filter(target == "2 wk ahead inc flu hosp")
threeweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 21, "-Flusight-ensemble.csv")) %>% filter(target == "3 wk ahead inc flu hosp")
fourweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 28, "-Flusight-ensemble.csv")) %>% filter(target == "4 wk ahead inc flu hosp")
cov.dat1 <- data.frame(rbind(oneweek, twoweek, threeweek, fourweek))
cov.dat1$location_name <- location_names$location_name[match(cov.dat1$location, location_names$location)]
cov.dat <- cov.dat1 %>%
mutate(value = case_when(quantile==0.5 ~ round(value),
quantile<0.5 ~ floor(value),
quantile>0.5 ~ ceiling(value),
type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, target, sep = "_")) %>%
dplyr::select(target, target_end_date, forecast_date, location_name, c(7:27)) %>%
group_by(target, target_end_date, forecast_date, location_name) %>%
summarise_all(sum, na.rm = T)
cov.dat$location_name <- ifelse(cov.dat$location_name == "US", "National", cov.dat$location_name)
cov.dat <- left_join(cov.dat, obs_data1, by = c("target_end_date" = "wk_end_date", "location_name" = "location_name"))
cov.dat$coverage.50 = ifelse(cov.dat$value >= cov.dat$quantile_0.25 & cov.dat$value <= cov.dat$quantile_0.75,T,F)
cov.dat$coverage.95 = ifelse(cov.dat$value >= cov.dat$quantile_0.025 & cov.dat$value <= cov.dat$quantile_0.975,T,F)
Percent.Cov.95 <- cov.dat %>% group_by(target, target_end_date) %>%
summarize(Score = round(100*mean(coverage.95, na.rm = T)))
old <- read.csv(paste0(dashpath,"/Coverage/pastCoverage2022-2023.csv"))[,-c(1)]
old$target_end_date <- as.Date(old$target_end_date, format = "%Y-%m-%d")
Percent.Cov.95 <- unique(data.frame(rbind(Percent.Cov.95, old)))
Percent.Cov.95 <- Percent.Cov.95 %>% dplyr::filter(target_end_date <= as.Date(forecast_date)+30) %>% dplyr::filter(is.na(Score) == F) %>% arrange(target_end_date)
#write.csv(Percent.Cov.95, paste0(dashpath,"/Coverage/pastCoverage2022-2023.csv"))
pacman::p_load(
tidyverse,
flexdashboard,
shiny,
plotly,
sf,
tmap,
ggplot2,
RColorBrewer,
raster,
ggtext,
forcats,
grid,
tidyquant,
RSocrata,
covidHubUtils,
hubEnsembles,
xlsx,
kableExtra
)
userid <- "rpe5"
forecast_date = "2023-01-30" # Monday
options(scipen = 999)
flusight_path <- paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-forecast-data/")
obspath <- paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-forecast-data/data-truth")
dashpath <- paste0("C:/Users/",userid,"/Desktop/GitHub/Flu-Visualizations/Dashboard R Code")
#sixweeks_before_forecast_date = "2022-05-09" # 6 weeks ago Monday
ensemble_code_path = paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-ensemble")
source("C:/Users/rpe5/Desktop/GitHub/Flu-Visualizations/Dashboard R Code/Dashboard Functions.R")
output_dir <- paste0(ensemble_code_path, "/", forecast_date, "/")
cast_target = c(paste(1:4, "wk inc flu hosp"))
location_names <- read.csv(paste0(flusight_path, "/data-locations/locations.csv"))
obs <- read.csv(paste0("C:/Users/",userid,"/Desktop/GitHub/Flusight-forecast-data/data-truth/truth-Incident Hospitalizations.csv")) %>%
mutate(wk_end_date = get_next_saturday(as.POSIXct(date, "%y/%m/%d")),
location_name = ifelse(location == 'US', 'National', location_name)) %>%
filter(date <= forecast_date) %>%
filter(date >= as.Date("2022-08-29", format = "%Y-%m-%d")) %>%
dplyr::select(-date) %>%
group_by(location_name, wk_end_date) %>%
summarise(value = sum(value)) %>%
ungroup()
obs_data1 <- obs
oneweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 7, "-Flusight-ensemble.csv")) %>% filter(target == "1 wk ahead inc flu hosp")
twoweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 14, "-Flusight-ensemble.csv")) %>% filter(target == "2 wk ahead inc flu hosp")
threeweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 21, "-Flusight-ensemble.csv")) %>% filter(target == "3 wk ahead inc flu hosp")
fourweek <- read.csv(paste0(flusight_path,"/data-forecasts/Flusight-ensemble/", as.Date(forecast_date) - 28, "-Flusight-ensemble.csv")) %>% filter(target == "4 wk ahead inc flu hosp")
cov.dat1 <- data.frame(rbind(oneweek, twoweek, threeweek, fourweek))
cov.dat1$location_name <- location_names$location_name[match(cov.dat1$location, location_names$location)]
cov.dat <- cov.dat1 %>%
mutate(value = case_when(quantile==0.5 ~ round(value),
quantile<0.5 ~ floor(value),
quantile>0.5 ~ ceiling(value),
type=='point' ~ round(value))) %>%
pivot_wider(names_from = c(type, quantile), values_from=value, values_fill = 0) %>%
mutate(target_end_date = as.Date(target_end_date),
forecast_date = as.Date(forecast_date),
id=paste(location, target, sep = "_")) %>%
dplyr::select(target, target_end_date, forecast_date, location_name, c(7:27)) %>%
group_by(target, target_end_date, forecast_date, location_name) %>%
summarise_all(sum, na.rm = T)
cov.dat$location_name <- ifelse(cov.dat$location_name == "US", "National", cov.dat$location_name)
cov.dat <- left_join(cov.dat, obs_data1, by = c("target_end_date" = "wk_end_date", "location_name" = "location_name"))
cov.dat$coverage.50 = ifelse(cov.dat$value >= cov.dat$quantile_0.25 & cov.dat$value <= cov.dat$quantile_0.75,T,F)
cov.dat$coverage.95 = ifelse(cov.dat$value >= cov.dat$quantile_0.025 & cov.dat$value <= cov.dat$quantile_0.975,T,F)
Percent.Cov.95 <- cov.dat %>% group_by(target, target_end_date) %>%
summarize(Score = round(100*mean(coverage.95, na.rm = T)))
old <- read.csv(paste0(dashpath,"/Coverage/pastCoverage2022-2023.csv"))[,-c(1)]
old$target_end_date <- as.Date(old$target_end_date, format = "%Y-%m-%d")
Percent.Cov.95 <- unique(data.frame(rbind(Percent.Cov.95, old)))
Percent.Cov.95 <- Percent.Cov.95 %>% dplyr::filter(target_end_date <= as.Date(forecast_date)+30) %>% dplyr::filter(is.na(Score) == F) %>% arrange(target_end_date)
#write.csv(Percent.Cov.95, paste0(dashpath,"/Coverage/pastCoverage2022-2023.csv"))
View(Percent.Cov.95)
